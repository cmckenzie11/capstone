{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Capstone_files/train/NORMAL/IM-0115-0001.jpeg'\n",
    "image1 = io.imread(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to grayscale, resize and normalize all images from a folder\n",
    "\n",
    "def img_process(folder, size):\n",
    "    \"\"\"Accepts an folder path as input and returns a list of all images in that folder \n",
    "    in grayscale, resized to square x by x dimensions with normalized pixel values\"\"\"\n",
    "    imageset = io.imread_collection(folder)\n",
    "    normed_images = []\n",
    "    for i in range(0,len(imageset)):\n",
    "        try:\n",
    "            rgb = gray2rgb(imageset[i])\n",
    "        except:\n",
    "            rgb = imageset[i]\n",
    "        resized = resize(rgb, (size,size))\n",
    "#        normed = StandardScaler().fit(resized) #NOTE: I will need to edit this so the images are normalized AFTER this function, so I can use the mean/std from the training set on the others.\n",
    "        normed_images.append(resized)\n",
    "    return normed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate category labels for each image set\n",
    "\n",
    "def generate_labels(set1, set2):\n",
    "    \"\"\"Takes image sets in different categories and returns a list of binary labels\"\"\"\n",
    "    labels = []\n",
    "    for i in range(len(set1)):\n",
    "        labels.append(0)\n",
    "    for j in range(len(set2)):\n",
    "        labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert a list of values to a tensorflow dataset\n",
    "\n",
    "def generate_tf_data(data):\n",
    "    \"\"\"Accepts a list or array of data and converts it to a TensorFlow dataset object\"\"\"\n",
    "    tensors = [tf.convert_to_tensor(x) for x in data]\n",
    "    dataset = tf.data.Dataset.from_tensors(tensors)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and processing image sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Process the normal training set\n",
    "folder = '../Capstone_files/train/NORMAL/*.jpeg'\n",
    "training_n = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Process the pneumonia training set\n",
    "folder = '../Capstone_files/train/PNEUMONIA/*.jpeg'\n",
    "training_p = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341\n",
      "3875\n",
      "1341\n",
      "5216\n",
      "training baseline: 0.7429064417177914\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the images into one set, confirm size of subsets and calculate baseline accuracy for this set\n",
    "train_images = training_n + training_p\n",
    "train_labels = generate_labels(training_n, training_p)\n",
    "#Also create sets with undersampling on the pneumonia set to address imbalance\n",
    "train_images_usample = training_n + training_p[:1341]\n",
    "train_labels_usample = generate_labels(training_n, training_p[:1341])\n",
    "print(len(training_n))\n",
    "print(len(training_p))\n",
    "print(len(training_p[:1341]))\n",
    "print(len(train_images))\n",
    "baseline_train = (len(training_p)/len(train_images))\n",
    "print('training baseline: ' + str(baseline_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Repeat the process for the test images\n",
    "folder = '../Capstone_files/test/NORMAL/*.jpeg'\n",
    "test_n = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "folder = '../Capstone_files/test/PNEUMONIA/*.jpeg'\n",
    "test_p = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "390\n",
      "624\n",
      "test baseline: 0.625\n"
     ]
    }
   ],
   "source": [
    "test_images = test_n + test_p\n",
    "test_labels = generate_labels(test_n, test_p)\n",
    "print(len(test_n))\n",
    "print(len(test_p))\n",
    "print(len(test_images))\n",
    "baseline_test = (len(test_p)/len(test_images))\n",
    "print('test baseline: ' + str(baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#And finally the validation set\n",
    "folder = '../Capstone_files/val/NORMAL/*.jpeg'\n",
    "val_n = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "folder = '../Capstone_files/val/PNEUMONIA/*.jpeg'\n",
    "val_p = img_process(folder, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "16\n",
      "validation baseline: 0.5\n"
     ]
    }
   ],
   "source": [
    "val_images = val_n + val_p\n",
    "val_labels = generate_labels(val_n, val_p)\n",
    "print(len(val_n))\n",
    "print(len(val_p))\n",
    "print(len(val_images))\n",
    "baseline_val = (len(val_p)/len(val_images))\n",
    "print('validation baseline: ' + str(baseline_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data input for TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate training datasets\n",
    "X_train = generate_tf_data(train_images)\n",
    "y_train = generate_tf_data(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate undersampled arrays\n",
    "X_train_array = np.array(train_images_usample).reshape(-1, 224, 224, 3)\n",
    "y_train_array = np.array(train_labels_usample).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_array_k = keras.utils.to_categorical(y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_images).reshape(-1, 224, 224, 3)\n",
    "y_test = np.array(test_labels).reshape(-1,)\n",
    "y_test_k = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a simple CNN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 2\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.ResNet50(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape, data_format='channels_last'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1000, activation='relu'))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 624 samples\n",
      "Epoch 1/5\n",
      "2682/2682 [==============================] - 373s 139ms/step - loss: 7.8650 - acc: 0.5022 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 2/5\n",
      "2682/2682 [==============================] - 341s 127ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 3/5\n",
      "2682/2682 [==============================] - 347s 129ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 4/5\n",
      "2682/2682 [==============================] - 342s 128ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.0738 - val_acc: 0.3750\n",
      "Epoch 5/5\n",
      "2682/2682 [==============================] - 344s 128ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 10.0738 - val_acc: 0.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a7749c9940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_array_k,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test_k),\n",
    "          callbacks=[history])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
